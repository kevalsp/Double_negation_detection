{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "Ch7MWkrPMzud",
    "outputId": "76286f8e-77bc-42d6-853d-ef61174f5fea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# connect google colab notebook with my google drive \n",
    "\n",
    "# Load the Drive helper and mount\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "a78SxuRuNx_y",
    "outputId": "200f7c4f-3d83-45dd-c4ba-79ecf0d4a5f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "V42Ozly8ORGg",
    "outputId": "bcfdfafe-fe78-48f4-d0e2-e1c8535260c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive\n"
     ]
    }
   ],
   "source": [
    "cd drive/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "aJzyhNIMOSuD",
    "outputId": "355cea8a-f5fd-4b80-8e22-efc672d07231"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive\n"
     ]
    }
   ],
   "source": [
    "cd My\\ Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "8zsKdGiwOXPh",
    "outputId": "7df28880-4910-45e5-80bb-559f062997d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34m'Anyfile Notepad Files'\u001b[0m/\n",
      " \u001b[01;34mcolab_file\u001b[0m/\n",
      "\u001b[01;34m'Colab Notebooks'\u001b[0m/\n",
      " \u001b[01;34mData\u001b[0m/\n",
      "'Getting started.pdf'\n",
      " MLP_GLoVe_new_data_k11.ipynb\n",
      " \u001b[01;34mpytorch-pretrained-BERT_k\u001b[0m/\n",
      "'run_classifier_dataset_utils (10).cpython-36.pyc'\n",
      "'run_classifier_dataset_utils (11).cpython-36.pyc'\n",
      "'run_classifier_dataset_utils (12).cpython-36.pyc'\n",
      "'run_classifier_dataset_utils (13).cpython-36.pyc'\n",
      "'run_classifier_dataset_utils (14).cpython-36.pyc'\n",
      "'run_classifier_dataset_utils (15).cpython-36.pyc'\n",
      "'run_classifier_dataset_utils (16).cpython-36.pyc'\n",
      "'run_classifier_dataset_utils (17).cpython-36.pyc'\n",
      "'run_classifier_dataset_utils (18).cpython-36.pyc'\n",
      "'run_classifier_dataset_utils (19).cpython-36.pyc'\n",
      "'run_classifier_dataset_utils (1).cpython-36.pyc'\n",
      "'run_classifier_dataset_utils (20).cpython-36.pyc'\n",
      "'run_classifier_dataset_utils (21).cpython-36.pyc'\n",
      "'run_classifier_dataset_utils (22).cpython-36.pyc'\n",
      "'run_classifier_dataset_utils (2).cpython-36.pyc'\n",
      "'run_classifier_dataset_utils (3).cpython-36.pyc'\n",
      "'run_classifier_dataset_utils (4).cpython-36.pyc'\n",
      "'run_classifier_dataset_utils (5).cpython-36.pyc'\n",
      "'run_classifier_dataset_utils (6).cpython-36.pyc'\n",
      "'run_classifier_dataset_utils (7).cpython-36.pyc'\n",
      "'run_classifier_dataset_utils (8).cpython-36.pyc'\n",
      "'run_classifier_dataset_utils (9).cpython-36.pyc'\n",
      " run_classifier_dataset_utils.cpython-36.pyc\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "z-_0-ll2OUkM",
    "outputId": "fb525b98-f855-4154-b812-57a76c46f437"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/pytorch-pretrained-BERT_k\n"
     ]
    }
   ],
   "source": [
    "cd pytorch-pretrained-BERT_k/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "nud-o8zSOWA6",
    "outputId": "121cd703-a9e5-4701-cfdc-81ee893052c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " bertology.py                             \u001b[0m\u001b[01;34mLasttry_cv_test_data\u001b[0m/\n",
      "'Copy of extract_pooled_features_re.py'   LICENSE\n",
      " \u001b[01;34mdata_pooled_features\u001b[0m/                    MANIFEST.in\n",
      " \u001b[01;34mdocker\u001b[0m/                                  \u001b[01;34mnotebooks\u001b[0m/\n",
      " \u001b[01;34mdocs\u001b[0m/                                   \u001b[01;34m'old_5-fold CV'\u001b[0m/\n",
      " \u001b[01;34mexamples\u001b[0m/                                \u001b[01;34m__pycache__\u001b[0m/\n",
      " extract_features.py                      \u001b[01;34mpytorch_pretrained_bert\u001b[0m/\n",
      " extract_pooled_features_re.py            README.md\n",
      " \u001b[01;34mfinetuned_bert\u001b[0m/                          requirements.txt\n",
      " \u001b[01;34mfinetuned_bert2\u001b[0m/                         run_classifier_dataset_utils.py\n",
      " \u001b[01;34mfinetuned_fold1\u001b[0m/                         run_classifier_py.py\n",
      " \u001b[01;34mfinetuned_fold2\u001b[0m/                         run_classifier_re.py\n",
      " \u001b[01;34mfinetuned_fold3\u001b[0m/                         run_gpt2.py\n",
      " \u001b[01;34mfinetuned_fold4\u001b[0m/                         run_openai_gpt.py\n",
      " \u001b[01;34mfinetuned_fold5\u001b[0m/                         \u001b[01;34mruns\u001b[0m/\n",
      " \u001b[01;34mfinetuned_lasttry_cv_test_data\u001b[0m/          run_squad_dataset_utils.py\n",
      " \u001b[01;34mfold1\u001b[0m/                                   run_squad.py\n",
      " \u001b[01;34mfold2\u001b[0m/                                   run_swag.py\n",
      " \u001b[01;34mfold3\u001b[0m/                                   run_transfo_xl.py\n",
      " \u001b[01;34mfold4\u001b[0m/                                   \u001b[01;34msamples\u001b[0m/\n",
      " \u001b[01;34mfold5\u001b[0m/                                   setup.py\n",
      " hubconf.py                               \u001b[01;34mtests\u001b[0m/\n",
      " \u001b[01;34mhubconfs\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "DqT-bxZeOd0P",
    "outputId": "f0dd2722-494e-4a94-bac2-cf68db23dc41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting regex\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/8e/cbf2295643d7265e7883326fb4654e643bfc93b3a8a8274d8010a39d8804/regex-2019.11.1-cp36-cp36m-manylinux1_x86_64.whl (643kB)\n",
      "\u001b[K     |████████████████████████████████| 645kB 2.8MB/s \n",
      "\u001b[?25hInstalling collected packages: regex\n",
      "Successfully installed regex-2019.11.1\n"
     ]
    }
   ],
   "source": [
    "!pip install regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "vVm207PQXCCP",
    "outputId": "aa4c93e2-8964-4713-e66a-c00004ac96a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 591.8MB 29kB/s \n",
      "\u001b[31mERROR: torchvision 0.4.2 has requirement torch==1.3.1, but you'll have torch 1.0.0 which is incompatible.\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q torch==1.0.0 torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "i3Rl5oRCt_MC",
    "outputId": "abacd96b-f654-4ddb-e8ff-a8b0c24f2aa3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorboardX\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/5c/e918d9f190baab8d55bad52840d8091dd5114cc99f03eaa6d72d404503cc/tensorboardX-1.9-py2.py3-none-any.whl (190kB)\n",
      "\r",
      "\u001b[K     |█▊                              | 10kB 21.5MB/s eta 0:00:01\r",
      "\u001b[K     |███▍                            | 20kB 1.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████▏                          | 30kB 2.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████▉                         | 40kB 1.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████▋                       | 51kB 2.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▎                     | 61kB 2.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 71kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▊                  | 81kB 3.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▌                | 92kB 3.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▏              | 102kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 112kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▋           | 122kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▍         | 133kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████        | 143kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▊      | 153kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▌    | 163kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▏  | 174kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████ | 184kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 194kB 2.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.10.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.17.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX) (42.0.1)\n",
      "Installing collected packages: tensorboardX\n",
      "Successfully installed tensorboardX-1.9\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Nml_gdijG8-N",
    "outputId": "e91b6585-2753-4a78-b866-a16ffb65c433"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'input_data_same/'\n",
      "/content/drive/My Drive/pytorch-pretrained-BERT_k\n"
     ]
    }
   ],
   "source": [
    "cd input_data_same/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9fvo0dbSt_Sy",
    "outputId": "379cd006-88e6-4f01-8972-4e769c0ae543"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev.tsv\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1NYAYPwdpcPy",
    "outputId": "15624cc9-7988-4745-c01e-a7913a056724"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/DN_PyTorch/pytorch-pretrained-BERT_k\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DmKVDfD5rhaS"
   },
   "outputs": [],
   "source": [
    "!rm -r finetuned_new_uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "0PwkKzfot_Ku",
    "outputId": "954881d5-9e9f-45ec-8f92-585735e4d22b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/06/2019 18:24:22 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "12/06/2019 18:24:23 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "12/06/2019 18:24:25 - INFO - pytorch_pretrained_bert.modeling -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_pretrained_bert/distributed_-1/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "12/06/2019 18:24:25 - INFO - pytorch_pretrained_bert.modeling -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_pretrained_bert/distributed_-1/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c\n",
      "12/06/2019 18:24:25 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "12/06/2019 18:24:29 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "12/06/2019 18:24:29 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "12/06/2019 18:24:31 - INFO - __main__ -   Writing example 0 of 2611\n",
      "12/06/2019 18:24:31 - INFO - __main__ -   *** Example ***\n",
      "12/06/2019 18:24:31 - INFO - __main__ -   guid: train-1\n",
      "12/06/2019 18:24:31 - INFO - __main__ -   tokens: [CLS] the video are long and not engaging enough rather than digital marketing concept this wa more an application of trend to traditional marketing concept some of the topic are already outdated and some assignment were more applicable to those residing in the u s or are not exactly feasible to do at this point [SEP]\n",
      "12/06/2019 18:24:31 - INFO - __main__ -   input_ids: 101 1996 2678 2024 2146 1998 2025 11973 2438 2738 2084 3617 5821 4145 2023 11333 2062 2019 4646 1997 9874 2000 3151 5821 4145 2070 1997 1996 8476 2024 2525 25963 1998 2070 8775 2020 2062 12711 2000 2216 7154 1999 1996 1057 1055 2030 2024 2025 3599 22945 2000 2079 2012 2023 2391 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/06/2019 18:24:31 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/06/2019 18:24:31 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/06/2019 18:24:31 - INFO - __main__ -   label: 1 (id = 1)\n",
      "12/06/2019 18:24:31 - INFO - __main__ -   *** Example ***\n",
      "12/06/2019 18:24:31 - INFO - __main__ -   guid: train-2\n",
      "12/06/2019 18:24:31 - INFO - __main__ -   tokens: [CLS] it wa fast but provided a good overview i would like some case to work and to apply the method to [SEP]\n",
      "12/06/2019 18:24:31 - INFO - __main__ -   input_ids: 101 2009 11333 3435 2021 3024 1037 2204 19184 1045 2052 2066 2070 2553 2000 2147 1998 2000 6611 1996 4118 2000 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/06/2019 18:24:31 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/06/2019 18:24:31 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/06/2019 18:24:31 - INFO - __main__ -   label: 2 (id = 2)\n",
      "12/06/2019 18:24:31 - INFO - __main__ -   *** Example ***\n",
      "12/06/2019 18:24:31 - INFO - __main__ -   guid: train-3\n",
      "12/06/2019 18:24:31 - INFO - __main__ -   tokens: [CLS] half of the link to external reading and video did not work which is the reason i did not complete the course it made taking the quiz fairly impossible unless i wanted to spend my time goo ##gling the answer [SEP]\n",
      "12/06/2019 18:24:31 - INFO - __main__ -   input_ids: 101 2431 1997 1996 4957 2000 6327 3752 1998 2678 2106 2025 2147 2029 2003 1996 3114 1045 2106 2025 3143 1996 2607 2009 2081 2635 1996 19461 7199 5263 4983 1045 2359 2000 5247 2026 2051 27571 18483 1996 3437 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/06/2019 18:24:31 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/06/2019 18:24:31 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/06/2019 18:24:31 - INFO - __main__ -   label: 1 (id = 1)\n",
      "12/06/2019 18:24:31 - INFO - __main__ -   *** Example ***\n",
      "12/06/2019 18:24:31 - INFO - __main__ -   guid: train-4\n",
      "12/06/2019 18:24:31 - INFO - __main__ -   tokens: [CLS] the course cover very useful and interesting topic not in very much detail though it is useful to begin with the topic but it is really not more that a thin introduction [SEP]\n",
      "12/06/2019 18:24:31 - INFO - __main__ -   input_ids: 101 1996 2607 3104 2200 6179 1998 5875 8476 2025 1999 2200 2172 6987 2295 2009 2003 6179 2000 4088 2007 1996 8476 2021 2009 2003 2428 2025 2062 2008 1037 4857 4955 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/06/2019 18:24:31 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/06/2019 18:24:31 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/06/2019 18:24:31 - INFO - __main__ -   label: 1 (id = 1)\n",
      "12/06/2019 18:24:31 - INFO - __main__ -   *** Example ***\n",
      "12/06/2019 18:24:31 - INFO - __main__ -   guid: train-5\n",
      "12/06/2019 18:24:31 - INFO - __main__ -   tokens: [CLS] please we all have accent but i can not understand some word and make it more difficult [SEP]\n",
      "12/06/2019 18:24:31 - INFO - __main__ -   input_ids: 101 3531 2057 2035 2031 9669 2021 1045 2064 2025 3305 2070 2773 1998 2191 2009 2062 3697 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/06/2019 18:24:31 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/06/2019 18:24:31 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/06/2019 18:24:31 - INFO - __main__ -   label: 1 (id = 1)\n",
      "12/06/2019 18:24:33 - INFO - __main__ -   ***** Running training *****\n",
      "12/06/2019 18:24:33 - INFO - __main__ -     Num examples = 2611\n",
      "12/06/2019 18:24:33 - INFO - __main__ -     Batch size = 32\n",
      "12/06/2019 18:24:33 - INFO - __main__ -     Num steps = 243\n",
      "Epoch:   0% 0/3 [00:00<?, ?it/s]\n",
      "Iteration:   0% 0/82 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   1% 1/82 [00:01<02:11,  1.62s/it]\u001b[A\n",
      "Iteration:   2% 2/82 [00:03<02:06,  1.58s/it]\u001b[A\n",
      "Iteration:   4% 3/82 [00:04<02:01,  1.54s/it]\u001b[A\n",
      "Iteration:   5% 4/82 [00:06<01:58,  1.52s/it]\u001b[A\n",
      "Iteration:   6% 5/82 [00:07<01:55,  1.50s/it]\u001b[A\n",
      "Iteration:   7% 6/82 [00:08<01:53,  1.50s/it]\u001b[A\n",
      "Iteration:   9% 7/82 [00:10<01:51,  1.49s/it]\u001b[A\n",
      "Iteration:  10% 8/82 [00:11<01:49,  1.48s/it]\u001b[A\n",
      "Iteration:  11% 9/82 [00:13<01:47,  1.47s/it]\u001b[A\n",
      "Iteration:  12% 10/82 [00:14<01:45,  1.47s/it]\u001b[A\n",
      "Iteration:  13% 11/82 [00:16<01:44,  1.47s/it]\u001b[A\n",
      "Iteration:  15% 12/82 [00:17<01:42,  1.47s/it]\u001b[A\n",
      "Iteration:  16% 13/82 [00:19<01:41,  1.47s/it]\u001b[A\n",
      "Iteration:  17% 14/82 [00:20<01:39,  1.47s/it]\u001b[A\n",
      "Iteration:  18% 15/82 [00:22<01:38,  1.47s/it]\u001b[A\n",
      "Iteration:  20% 16/82 [00:23<01:37,  1.47s/it]\u001b[A\n",
      "Iteration:  21% 17/82 [00:25<01:35,  1.47s/it]\u001b[A\n",
      "Iteration:  22% 18/82 [00:26<01:34,  1.47s/it]\u001b[A\n",
      "Iteration:  23% 19/82 [00:28<01:32,  1.47s/it]\u001b[A\n",
      "Iteration:  24% 20/82 [00:29<01:31,  1.48s/it]\u001b[A\n",
      "Iteration:  26% 21/82 [00:31<01:30,  1.48s/it]\u001b[A\n",
      "Iteration:  27% 22/82 [00:32<01:28,  1.48s/it]\u001b[A\n",
      "Iteration:  28% 23/82 [00:34<01:27,  1.48s/it]\u001b[A\n",
      "Iteration:  29% 24/82 [00:35<01:26,  1.49s/it]\u001b[A\n",
      "Iteration:  30% 25/82 [00:36<01:24,  1.48s/it]\u001b[A\n",
      "Iteration:  32% 26/82 [00:38<01:23,  1.49s/it]\u001b[A\n",
      "Iteration:  33% 27/82 [00:39<01:21,  1.48s/it]\u001b[A\n",
      "Iteration:  34% 28/82 [00:41<01:20,  1.48s/it]\u001b[A\n",
      "Iteration:  35% 29/82 [00:42<01:18,  1.49s/it]\u001b[A\n",
      "Iteration:  37% 30/82 [00:44<01:17,  1.49s/it]\u001b[A\n",
      "Iteration:  38% 31/82 [00:45<01:15,  1.49s/it]\u001b[A\n",
      "Iteration:  39% 32/82 [00:47<01:14,  1.49s/it]\u001b[A\n",
      "Iteration:  40% 33/82 [00:48<01:12,  1.49s/it]\u001b[A\n",
      "Iteration:  41% 34/82 [00:50<01:11,  1.49s/it]\u001b[A\n",
      "Iteration:  43% 35/82 [00:51<01:10,  1.49s/it]\u001b[A\n",
      "Iteration:  44% 36/82 [00:53<01:08,  1.49s/it]\u001b[A\n",
      "Iteration:  45% 37/82 [00:54<01:07,  1.49s/it]\u001b[A\n",
      "Iteration:  46% 38/82 [00:56<01:05,  1.49s/it]\u001b[A\n",
      "Iteration:  48% 39/82 [00:57<01:04,  1.49s/it]\u001b[A\n",
      "Iteration:  49% 40/82 [00:59<01:02,  1.49s/it]\u001b[A\n",
      "Iteration:  50% 41/82 [01:00<01:01,  1.49s/it]\u001b[A\n",
      "Iteration:  51% 42/82 [01:02<00:59,  1.50s/it]\u001b[A\n",
      "Iteration:  52% 43/82 [01:03<00:58,  1.50s/it]\u001b[A\n",
      "Iteration:  54% 44/82 [01:05<00:56,  1.49s/it]\u001b[A\n",
      "Iteration:  55% 45/82 [01:06<00:55,  1.49s/it]\u001b[A\n",
      "Iteration:  56% 46/82 [01:08<00:53,  1.49s/it]\u001b[A\n",
      "Iteration:  57% 47/82 [01:09<00:52,  1.50s/it]\u001b[A\n",
      "Iteration:  59% 48/82 [01:11<00:50,  1.49s/it]\u001b[A\n",
      "Iteration:  60% 49/82 [01:12<00:49,  1.49s/it]\u001b[A\n",
      "Iteration:  61% 50/82 [01:14<00:47,  1.49s/it]\u001b[A\n",
      "Iteration:  62% 51/82 [01:15<00:46,  1.50s/it]\u001b[A\n",
      "Iteration:  63% 52/82 [01:17<00:44,  1.50s/it]\u001b[A\n",
      "Iteration:  65% 53/82 [01:18<00:43,  1.50s/it]\u001b[A\n",
      "Iteration:  66% 54/82 [01:20<00:41,  1.50s/it]\u001b[A\n",
      "Iteration:  67% 55/82 [01:21<00:40,  1.50s/it]\u001b[A\n",
      "Iteration:  68% 56/82 [01:23<00:39,  1.51s/it]\u001b[A\n",
      "Iteration:  70% 57/82 [01:24<00:37,  1.51s/it]\u001b[A\n",
      "Iteration:  71% 58/82 [01:26<00:36,  1.51s/it]\u001b[A\n",
      "Iteration:  72% 59/82 [01:27<00:34,  1.51s/it]\u001b[A\n",
      "Iteration:  73% 60/82 [01:29<00:33,  1.51s/it]\u001b[A\n",
      "Iteration:  74% 61/82 [01:30<00:31,  1.51s/it]\u001b[A\n",
      "Iteration:  76% 62/82 [01:32<00:30,  1.51s/it]\u001b[A\n",
      "Iteration:  77% 63/82 [01:33<00:28,  1.51s/it]\u001b[A\n",
      "Iteration:  78% 64/82 [01:35<00:27,  1.51s/it]\u001b[A\n",
      "Iteration:  79% 65/82 [01:36<00:25,  1.51s/it]\u001b[A\n",
      "Iteration:  80% 66/82 [01:38<00:24,  1.51s/it]\u001b[A\n",
      "Iteration:  82% 67/82 [01:39<00:22,  1.51s/it]\u001b[A\n",
      "Iteration:  83% 68/82 [01:41<00:21,  1.51s/it]\u001b[A\n",
      "Iteration:  84% 69/82 [01:42<00:19,  1.52s/it]\u001b[A\n",
      "Iteration:  85% 70/82 [01:44<00:18,  1.52s/it]\u001b[A\n",
      "Iteration:  87% 71/82 [01:46<00:16,  1.52s/it]\u001b[A\n",
      "Iteration:  88% 72/82 [01:47<00:15,  1.52s/it]\u001b[A\n",
      "Iteration:  89% 73/82 [01:49<00:13,  1.52s/it]\u001b[A\n",
      "Iteration:  90% 74/82 [01:50<00:12,  1.52s/it]\u001b[A\n",
      "Iteration:  91% 75/82 [01:52<00:10,  1.51s/it]\u001b[A\n",
      "Iteration:  93% 76/82 [01:53<00:09,  1.51s/it]\u001b[A\n",
      "Iteration:  94% 77/82 [01:55<00:07,  1.51s/it]\u001b[A\n",
      "Iteration:  95% 78/82 [01:56<00:06,  1.51s/it]\u001b[A\n",
      "Iteration:  96% 79/82 [01:58<00:04,  1.51s/it]\u001b[A\n",
      "Iteration:  98% 80/82 [01:59<00:03,  1.51s/it]\u001b[A\n",
      "Iteration:  99% 81/82 [02:01<00:01,  1.51s/it]\u001b[A\n",
      "Iteration: 100% 82/82 [02:02<00:00,  1.35s/it]\u001b[A\n",
      "Epoch:  33% 1/3 [02:02<04:04, 122.09s/it]\n",
      "Iteration:   0% 0/82 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   1% 1/82 [00:01<02:01,  1.50s/it]\u001b[A\n",
      "Iteration:   2% 2/82 [00:03<02:00,  1.50s/it]\u001b[A\n",
      "Iteration:   4% 3/82 [00:04<01:58,  1.50s/it]\u001b[A\n",
      "Iteration:   5% 4/82 [00:05<01:56,  1.50s/it]\u001b[A\n",
      "Iteration:   6% 5/82 [00:07<01:55,  1.50s/it]\u001b[A\n",
      "Iteration:   7% 6/82 [00:08<01:53,  1.50s/it]\u001b[A\n",
      "Iteration:   9% 7/82 [00:10<01:52,  1.50s/it]\u001b[A\n",
      "Iteration:  10% 8/82 [00:12<01:51,  1.50s/it]\u001b[A\n",
      "Iteration:  11% 9/82 [00:13<01:49,  1.50s/it]\u001b[A\n",
      "Iteration:  12% 10/82 [00:15<01:48,  1.50s/it]\u001b[A\n",
      "Iteration:  13% 11/82 [00:16<01:46,  1.50s/it]\u001b[A\n",
      "Iteration:  15% 12/82 [00:17<01:45,  1.50s/it]\u001b[A\n",
      "Iteration:  16% 13/82 [00:19<01:43,  1.50s/it]\u001b[A\n",
      "Iteration:  17% 14/82 [00:21<01:42,  1.51s/it]\u001b[A\n",
      "Iteration:  18% 15/82 [00:22<01:41,  1.51s/it]\u001b[A\n",
      "Iteration:  20% 16/82 [00:24<01:39,  1.51s/it]\u001b[A\n",
      "Iteration:  21% 17/82 [00:25<01:37,  1.50s/it]\u001b[A\n",
      "Iteration:  22% 18/82 [00:27<01:36,  1.50s/it]\u001b[A\n",
      "Iteration:  23% 19/82 [00:28<01:34,  1.50s/it]\u001b[A\n",
      "Iteration:  24% 20/82 [00:30<01:33,  1.50s/it]\u001b[A\n",
      "Iteration:  26% 21/82 [00:31<01:31,  1.50s/it]\u001b[A\n",
      "Iteration:  27% 22/82 [00:33<01:30,  1.51s/it]\u001b[A\n",
      "Iteration:  28% 23/82 [00:34<01:28,  1.50s/it]\u001b[A\n",
      "Iteration:  29% 24/82 [00:36<01:27,  1.50s/it]\u001b[A\n",
      "Iteration:  30% 25/82 [00:37<01:25,  1.50s/it]\u001b[A\n",
      "Iteration:  32% 26/82 [00:39<01:24,  1.50s/it]\u001b[A\n",
      "Iteration:  33% 27/82 [00:40<01:22,  1.50s/it]\u001b[A\n",
      "Iteration:  34% 28/82 [00:42<01:21,  1.50s/it]\u001b[A\n",
      "Iteration:  35% 29/82 [00:43<01:20,  1.53s/it]\u001b[A\n",
      "Iteration:  37% 30/82 [00:45<01:19,  1.53s/it]\u001b[A\n",
      "Iteration:  38% 31/82 [00:46<01:17,  1.52s/it]\u001b[A\n",
      "Iteration:  39% 32/82 [00:48<01:15,  1.51s/it]\u001b[A\n",
      "Iteration:  40% 33/82 [00:49<01:14,  1.51s/it]\u001b[A\n",
      "Iteration:  41% 34/82 [00:51<01:12,  1.51s/it]\u001b[A\n",
      "Iteration:  43% 35/82 [00:52<01:10,  1.51s/it]\u001b[A\n",
      "Iteration:  44% 36/82 [00:54<01:09,  1.50s/it]\u001b[A\n",
      "Iteration:  45% 37/82 [00:55<01:07,  1.50s/it]\u001b[A\n",
      "Iteration:  46% 38/82 [00:57<01:05,  1.50s/it]\u001b[A\n",
      "Iteration:  48% 39/82 [00:58<01:04,  1.50s/it]\u001b[A\n",
      "Iteration:  49% 40/82 [01:00<01:02,  1.50s/it]\u001b[A\n",
      "Iteration:  50% 41/82 [01:01<01:01,  1.50s/it]\u001b[A\n",
      "Iteration:  51% 42/82 [01:03<01:00,  1.51s/it]\u001b[A\n",
      "Iteration:  52% 43/82 [01:04<00:58,  1.50s/it]\u001b[A\n",
      "Iteration:  54% 44/82 [01:06<00:57,  1.50s/it]\u001b[A\n",
      "Iteration:  55% 45/82 [01:07<00:55,  1.50s/it]\u001b[A\n",
      "Iteration:  56% 46/82 [01:09<00:54,  1.51s/it]\u001b[A\n",
      "Iteration:  57% 47/82 [01:10<00:52,  1.50s/it]\u001b[A\n",
      "Iteration:  59% 48/82 [01:12<00:51,  1.50s/it]\u001b[A\n",
      "Iteration:  60% 49/82 [01:13<00:49,  1.50s/it]\u001b[A\n",
      "Iteration:  61% 50/82 [01:15<00:48,  1.50s/it]\u001b[A\n",
      "Iteration:  62% 51/82 [01:16<00:46,  1.50s/it]\u001b[A\n",
      "Iteration:  63% 52/82 [01:18<00:45,  1.50s/it]\u001b[A\n",
      "Iteration:  65% 53/82 [01:19<00:43,  1.50s/it]\u001b[A\n",
      "Iteration:  66% 54/82 [01:21<00:41,  1.49s/it]\u001b[A\n",
      "Iteration:  67% 55/82 [01:22<00:40,  1.50s/it]\u001b[A\n",
      "Iteration:  68% 56/82 [01:24<00:38,  1.49s/it]\u001b[A\n",
      "Iteration:  70% 57/82 [01:25<00:37,  1.49s/it]\u001b[A\n",
      "Iteration:  71% 58/82 [01:27<00:35,  1.50s/it]\u001b[A\n",
      "Iteration:  72% 59/82 [01:28<00:34,  1.50s/it]\u001b[A\n",
      "Iteration:  73% 60/82 [01:30<00:32,  1.50s/it]\u001b[A\n",
      "Iteration:  74% 61/82 [01:31<00:31,  1.50s/it]\u001b[A\n",
      "Iteration:  76% 62/82 [01:33<00:29,  1.50s/it]\u001b[A\n",
      "Iteration:  77% 63/82 [01:34<00:28,  1.50s/it]\u001b[A\n",
      "Iteration:  78% 64/82 [01:36<00:26,  1.50s/it]\u001b[A\n",
      "Iteration:  79% 65/82 [01:37<00:25,  1.50s/it]\u001b[A\n",
      "Iteration:  80% 66/82 [01:39<00:23,  1.50s/it]\u001b[A\n",
      "Iteration:  82% 67/82 [01:40<00:23,  1.53s/it]\u001b[A\n",
      "Iteration:  83% 68/82 [01:42<00:21,  1.53s/it]\u001b[A\n",
      "Iteration:  84% 69/82 [01:43<00:19,  1.52s/it]\u001b[A\n",
      "Iteration:  85% 70/82 [01:45<00:18,  1.52s/it]\u001b[A\n",
      "Iteration:  87% 71/82 [01:46<00:16,  1.51s/it]\u001b[A\n",
      "Iteration:  88% 72/82 [01:48<00:15,  1.51s/it]\u001b[A\n",
      "Iteration:  89% 73/82 [01:49<00:13,  1.51s/it]\u001b[A\n",
      "Iteration:  90% 74/82 [01:51<00:12,  1.51s/it]\u001b[A\n",
      "Iteration:  91% 75/82 [01:52<00:10,  1.50s/it]\u001b[A\n",
      "Iteration:  93% 76/82 [01:54<00:09,  1.50s/it]\u001b[A\n",
      "Iteration:  94% 77/82 [01:55<00:07,  1.50s/it]\u001b[A\n",
      "Iteration:  95% 78/82 [01:57<00:05,  1.50s/it]\u001b[A\n",
      "Iteration:  96% 79/82 [01:58<00:04,  1.50s/it]\u001b[A\n",
      "Iteration:  98% 80/82 [02:00<00:02,  1.50s/it]\u001b[A\n",
      "Iteration:  99% 81/82 [02:01<00:01,  1.50s/it]\u001b[A\n",
      "Iteration: 100% 82/82 [02:02<00:00,  1.34s/it]\u001b[A\n",
      "Epoch:  67% 2/3 [04:04<02:02, 122.30s/it]\n",
      "Iteration:   0% 0/82 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   1% 1/82 [00:01<02:01,  1.50s/it]\u001b[A\n",
      "Iteration:   2% 2/82 [00:02<01:59,  1.50s/it]\u001b[A\n",
      "Iteration:   4% 3/82 [00:04<01:58,  1.50s/it]\u001b[A\n",
      "Iteration:   5% 4/82 [00:05<01:56,  1.50s/it]\u001b[A\n",
      "Iteration:   6% 5/82 [00:07<01:55,  1.50s/it]\u001b[A\n",
      "Iteration:   7% 6/82 [00:09<01:54,  1.50s/it]\u001b[A\n",
      "Iteration:   9% 7/82 [00:10<01:52,  1.50s/it]\u001b[A\n",
      "Iteration:  10% 8/82 [00:12<01:51,  1.50s/it]\u001b[A\n",
      "Iteration:  11% 9/82 [00:13<01:49,  1.50s/it]\u001b[A\n",
      "Iteration:  12% 10/82 [00:15<01:48,  1.50s/it]\u001b[A\n",
      "Iteration:  13% 11/82 [00:16<01:46,  1.50s/it]\u001b[A\n",
      "Iteration:  15% 12/82 [00:18<01:45,  1.51s/it]\u001b[A\n",
      "Iteration:  16% 13/82 [00:19<01:44,  1.51s/it]\u001b[A\n",
      "Iteration:  17% 14/82 [00:21<01:42,  1.51s/it]\u001b[A\n",
      "Iteration:  18% 15/82 [00:22<01:41,  1.51s/it]\u001b[A\n",
      "Iteration:  20% 16/82 [00:24<01:39,  1.51s/it]\u001b[A\n",
      "Iteration:  21% 17/82 [00:25<01:38,  1.51s/it]\u001b[A\n",
      "Iteration:  22% 18/82 [00:27<01:36,  1.51s/it]\u001b[A\n",
      "Iteration:  23% 19/82 [00:28<01:34,  1.50s/it]\u001b[A\n",
      "Iteration:  24% 20/82 [00:30<01:32,  1.50s/it]\u001b[A\n",
      "Iteration:  26% 21/82 [00:31<01:31,  1.50s/it]\u001b[A\n",
      "Iteration:  27% 22/82 [00:33<01:29,  1.49s/it]\u001b[A\n",
      "Iteration:  28% 23/82 [00:34<01:28,  1.50s/it]\u001b[A\n",
      "Iteration:  29% 24/82 [00:36<01:26,  1.49s/it]\u001b[A\n",
      "Iteration:  30% 25/82 [00:37<01:25,  1.50s/it]\u001b[A\n",
      "Iteration:  32% 26/82 [00:39<01:23,  1.50s/it]\u001b[A\n",
      "Iteration:  33% 27/82 [00:40<01:22,  1.50s/it]\u001b[A\n",
      "Iteration:  34% 28/82 [00:42<01:20,  1.50s/it]\u001b[A\n",
      "Iteration:  35% 29/82 [00:43<01:19,  1.50s/it]\u001b[A\n",
      "Iteration:  37% 30/82 [00:45<01:18,  1.50s/it]\u001b[A\n",
      "Iteration:  38% 31/82 [00:46<01:16,  1.50s/it]\u001b[A\n",
      "Iteration:  39% 32/82 [00:48<01:14,  1.50s/it]\u001b[A\n",
      "Iteration:  40% 33/82 [00:49<01:13,  1.50s/it]\u001b[A\n",
      "Iteration:  41% 34/82 [00:51<01:11,  1.50s/it]\u001b[A\n",
      "Iteration:  43% 35/82 [00:52<01:10,  1.50s/it]\u001b[A\n",
      "Iteration:  44% 36/82 [00:54<01:09,  1.50s/it]\u001b[A\n",
      "Iteration:  45% 37/82 [00:55<01:07,  1.50s/it]\u001b[A\n",
      "Iteration:  46% 38/82 [00:57<01:06,  1.50s/it]\u001b[A\n",
      "Iteration:  48% 39/82 [00:58<01:04,  1.50s/it]\u001b[A\n",
      "Iteration:  49% 40/82 [01:00<01:03,  1.50s/it]\u001b[A\n",
      "Iteration:  50% 41/82 [01:01<01:01,  1.50s/it]\u001b[A\n",
      "Iteration:  51% 42/82 [01:03<01:00,  1.50s/it]\u001b[A\n",
      "Iteration:  52% 43/82 [01:04<00:58,  1.51s/it]\u001b[A\n",
      "Iteration:  54% 44/82 [01:06<00:57,  1.51s/it]\u001b[A\n",
      "Iteration:  55% 45/82 [01:07<00:55,  1.51s/it]\u001b[A\n",
      "Iteration:  56% 46/82 [01:09<00:54,  1.51s/it]\u001b[A\n",
      "Iteration:  57% 47/82 [01:10<00:52,  1.51s/it]\u001b[A\n",
      "Iteration:  59% 48/82 [01:12<00:51,  1.51s/it]\u001b[A\n",
      "Iteration:  60% 49/82 [01:13<00:49,  1.50s/it]\u001b[A\n",
      "Iteration:  61% 50/82 [01:15<00:48,  1.50s/it]\u001b[A\n",
      "Iteration:  62% 51/82 [01:16<00:46,  1.50s/it]\u001b[A\n",
      "Iteration:  63% 52/82 [01:18<00:44,  1.50s/it]\u001b[A\n",
      "Iteration:  65% 53/82 [01:19<00:43,  1.50s/it]\u001b[A\n",
      "Iteration:  66% 54/82 [01:21<00:42,  1.50s/it]\u001b[A\n",
      "Iteration:  67% 55/82 [01:22<00:40,  1.50s/it]\u001b[A\n",
      "Iteration:  68% 56/82 [01:24<00:39,  1.50s/it]\u001b[A\n",
      "Iteration:  70% 57/82 [01:25<00:37,  1.50s/it]\u001b[A\n",
      "Iteration:  71% 58/82 [01:27<00:35,  1.50s/it]\u001b[A\n",
      "Iteration:  72% 59/82 [01:28<00:34,  1.50s/it]\u001b[A\n",
      "Iteration:  73% 60/82 [01:30<00:33,  1.50s/it]\u001b[A\n",
      "Iteration:  74% 61/82 [01:31<00:31,  1.50s/it]\u001b[A\n",
      "Iteration:  76% 62/82 [01:33<00:30,  1.51s/it]\u001b[A\n",
      "Iteration:  77% 63/82 [01:34<00:28,  1.51s/it]\u001b[A\n",
      "Iteration:  78% 64/82 [01:36<00:27,  1.51s/it]\u001b[A\n",
      "Iteration:  79% 65/82 [01:37<00:25,  1.50s/it]\u001b[A\n",
      "Iteration:  80% 66/82 [01:39<00:24,  1.50s/it]\u001b[A\n",
      "Iteration:  82% 67/82 [01:40<00:22,  1.50s/it]\u001b[A\n",
      "Iteration:  83% 68/82 [01:42<00:20,  1.50s/it]\u001b[A\n",
      "Iteration:  84% 69/82 [01:43<00:19,  1.50s/it]\u001b[A\n",
      "Iteration:  85% 70/82 [01:45<00:17,  1.50s/it]\u001b[A\n",
      "Iteration:  87% 71/82 [01:46<00:16,  1.50s/it]\u001b[A\n",
      "Iteration:  88% 72/82 [01:48<00:14,  1.50s/it]\u001b[A\n",
      "Iteration:  89% 73/82 [01:49<00:13,  1.50s/it]\u001b[A\n",
      "Iteration:  90% 74/82 [01:51<00:11,  1.50s/it]\u001b[A\n",
      "Iteration:  91% 75/82 [01:52<00:10,  1.50s/it]\u001b[A\n",
      "Iteration:  93% 76/82 [01:54<00:08,  1.50s/it]\u001b[A\n",
      "Iteration:  94% 77/82 [01:55<00:07,  1.50s/it]\u001b[A\n",
      "Iteration:  95% 78/82 [01:57<00:05,  1.50s/it]\u001b[A\n",
      "Iteration:  96% 79/82 [01:58<00:04,  1.53s/it]\u001b[A\n",
      "Iteration:  98% 80/82 [02:00<00:03,  1.53s/it]\u001b[A12/06/2019 18:30:39 - WARNING - pytorch_pretrained_bert.optimization -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n",
      "\n",
      "Iteration:  99% 81/82 [02:01<00:01,  1.52s/it]\u001b[A12/06/2019 18:30:40 - WARNING - pytorch_pretrained_bert.optimization -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n",
      "\n",
      "Iteration: 100% 82/82 [02:02<00:00,  1.36s/it]\u001b[A\n",
      "Epoch: 100% 3/3 [06:07<00:00, 122.44s/it]\n",
      "12/06/2019 18:30:42 - INFO - pytorch_pretrained_bert.modeling -   loading weights file finetuned_for_pooled_features/pytorch_model.bin\n",
      "12/06/2019 18:30:42 - INFO - pytorch_pretrained_bert.modeling -   loading configuration file finetuned_for_pooled_features/config.json\n",
      "12/06/2019 18:30:42 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "12/06/2019 18:30:46 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file finetuned_for_pooled_features/vocab.txt\n"
     ]
    }
   ],
   "source": [
    "!python run_classifier_re.py --task_name SST-2 --bert_model bert-base-uncased --do_train --do_lower_case --data_dir data_pooled_features --max_seq_length 128 --train_batch_size 32 --learning_rate 1e-6 --num_train_epochs 3.0 --output_dir finetuned_for_pooled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "ghctVagfshYM",
    "outputId": "a7692fca-6720-4084-84f5-52a33b71b2ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " bertology.py                             \u001b[0m\u001b[01;34mhubconfs\u001b[0m/\n",
      "'Copy of extract_pooled_features_re.py'   \u001b[01;34mLasttry_cv_test_data\u001b[0m/\n",
      " \u001b[01;34mdata_pooled_features\u001b[0m/                    LICENSE\n",
      " \u001b[01;34mdocker\u001b[0m/                                  MANIFEST.in\n",
      " \u001b[01;34mdocs\u001b[0m/                                    \u001b[01;34mnotebooks\u001b[0m/\n",
      " \u001b[01;34mexamples\u001b[0m/                               \u001b[01;34m'old_5-fold CV'\u001b[0m/\n",
      " extract_features.py                      \u001b[01;34m__pycache__\u001b[0m/\n",
      " extract_pooled_features_re.py            \u001b[01;34mpytorch_pretrained_bert\u001b[0m/\n",
      " \u001b[01;34mfinetuned_bert\u001b[0m/                          README.md\n",
      " \u001b[01;34mfinetuned_bert2\u001b[0m/                         requirements.txt\n",
      " \u001b[01;34mfinetuned_fold1\u001b[0m/                         run_classifier_dataset_utils.py\n",
      " \u001b[01;34mfinetuned_fold2\u001b[0m/                         run_classifier_py.py\n",
      " \u001b[01;34mfinetuned_fold3\u001b[0m/                         run_classifier_re.py\n",
      " \u001b[01;34mfinetuned_fold4\u001b[0m/                         run_gpt2.py\n",
      " \u001b[01;34mfinetuned_fold5\u001b[0m/                         run_openai_gpt.py\n",
      " \u001b[01;34mfinetuned_for_pooled_features\u001b[0m/           \u001b[01;34mruns\u001b[0m/\n",
      " \u001b[01;34mfinetuned_lasttry_cv_test_data\u001b[0m/          run_squad_dataset_utils.py\n",
      " \u001b[01;34mfold1\u001b[0m/                                   run_squad.py\n",
      " \u001b[01;34mfold2\u001b[0m/                                   run_swag.py\n",
      " \u001b[01;34mfold3\u001b[0m/                                   run_transfo_xl.py\n",
      " \u001b[01;34mfold4\u001b[0m/                                   \u001b[01;34msamples\u001b[0m/\n",
      " \u001b[01;34mfold5\u001b[0m/                                   setup.py\n",
      " hubconf.py                               \u001b[01;34mtests\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "PsWYeu1i2ypV",
    "outputId": "5740d1ff-00f2-45c2-bc93-9da261c06a64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/06/2019 18:37:48 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "12/06/2019 18:37:48 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file finetuned_for_pooled_features/vocab.txt\n",
      "12/06/2019 18:37:48 - INFO - pytorch_pretrained_bert.modeling_re -   loading weights file finetuned_for_pooled_features/pytorch_model.bin\n",
      "12/06/2019 18:37:48 - INFO - pytorch_pretrained_bert.modeling_re -   loading configuration file finetuned_for_pooled_features/config.json\n",
      "12/06/2019 18:37:48 - INFO - pytorch_pretrained_bert.modeling_re -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "12/06/2019 18:37:55 - INFO - __main__ -   Writing example 0 of 653\n",
      "12/06/2019 18:37:55 - INFO - __main__ -   *** Example ***\n",
      "12/06/2019 18:37:55 - INFO - __main__ -   guid: dev-1\n",
      "12/06/2019 18:37:55 - INFO - __main__ -   tokens: [CLS] korean structured for anything studying i but and wa introduction nice self been not villain ##ous so never a to year a ve a off very little on i too [SEP]\n",
      "12/06/2019 18:37:55 - INFO - __main__ -   input_ids: 101 4759 14336 2005 2505 5702 1045 2021 1998 11333 4955 3835 2969 2042 2025 12700 3560 2061 2196 1037 2000 2095 1037 2310 1037 2125 2200 2210 2006 1045 2205 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/06/2019 18:37:55 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/06/2019 18:37:55 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/06/2019 18:37:55 - INFO - __main__ -   label: 0 (id = 0)\n",
      "12/06/2019 18:37:55 - INFO - __main__ -   *** Example ***\n",
      "12/06/2019 18:37:55 - INFO - __main__ -   guid: dev-2\n",
      "12/06/2019 18:37:55 - INFO - __main__ -   tokens: [CLS] have note nicely i wa done very not grace ##less course that i to [SEP]\n",
      "12/06/2019 18:37:55 - INFO - __main__ -   input_ids: 101 2031 3602 19957 1045 11333 2589 2200 2025 4519 3238 2607 2008 1045 2000 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/06/2019 18:37:55 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/06/2019 18:37:55 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/06/2019 18:37:55 - INFO - __main__ -   label: 0 (id = 0)\n",
      "12/06/2019 18:37:55 - INFO - __main__ -   *** Example ***\n",
      "12/06/2019 18:37:55 - INFO - __main__ -   guid: dev-3\n",
      "12/06/2019 18:37:55 - INFO - __main__ -   tokens: [CLS] very effective [SEP]\n",
      "12/06/2019 18:37:55 - INFO - __main__ -   input_ids: 101 2200 4621 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/06/2019 18:37:55 - INFO - __main__ -   input_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/06/2019 18:37:55 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/06/2019 18:37:55 - INFO - __main__ -   label: 2 (id = 2)\n",
      "12/06/2019 18:37:55 - INFO - __main__ -   *** Example ***\n",
      "12/06/2019 18:37:55 - INFO - __main__ -   guid: dev-4\n",
      "12/06/2019 18:37:55 - INFO - __main__ -   tokens: [CLS] thumb up learned something that i have never learnt before [SEP]\n",
      "12/06/2019 18:37:55 - INFO - __main__ -   input_ids: 101 7639 2039 4342 2242 2008 1045 2031 2196 20215 2077 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/06/2019 18:37:55 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/06/2019 18:37:55 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/06/2019 18:37:55 - INFO - __main__ -   label: 2 (id = 2)\n",
      "12/06/2019 18:37:55 - INFO - __main__ -   *** Example ***\n",
      "12/06/2019 18:37:55 - INFO - __main__ -   guid: dev-5\n",
      "12/06/2019 18:37:55 - INFO - __main__ -   tokens: [CLS] me gust ##o much ##o [SEP]\n",
      "12/06/2019 18:37:55 - INFO - __main__ -   input_ids: 101 2033 26903 2080 2172 2080 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/06/2019 18:37:55 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/06/2019 18:37:55 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/06/2019 18:37:55 - INFO - __main__ -   label: 2 (id = 2)\n",
      "12/06/2019 18:37:56 - INFO - __main__ -   ***** Running evaluation *****\n",
      "12/06/2019 18:37:56 - INFO - __main__ -     Num examples = 653\n",
      "12/06/2019 18:37:56 - INFO - __main__ -     Batch size = 8\n",
      "Evaluating: 100% 82/82 [00:10<00:00,  8.07it/s]\n",
      "Extracted pooled features for dev set, congratulations!\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([653, 768])\n",
      "dev features type :  <class 'numpy.ndarray'>\n",
      "dev features shape :  (653, 768)\n",
      "dev_labels type :  <class 'numpy.ndarray'>\n",
      "dev_labels length :  653\n",
      "12/06/2019 18:38:06 - INFO - __main__ -   Writing example 0 of 816\n",
      "12/06/2019 18:38:06 - INFO - __main__ -   *** Example ***\n",
      "12/06/2019 18:38:06 - INFO - __main__ -   guid: test-1\n",
      "12/06/2019 18:38:06 - INFO - __main__ -   tokens: [CLS] worse not cursed to were incomplete work some impossible to have and at part forum describe video the n t the upon on s and of wa the to the thing a which given point exercise those assignment of are done instruction a the this n t it me re ##media ##l in you s for n t these the get instruction i still error version extra s assignment all code gave build material to course be ago issue of of begin in the project exercise hour just how using even written the even much of there the it some file new too get the these that ca flag ##ged code also course updated it so in are file month working are wo match complete work [SEP]\n",
      "12/06/2019 18:38:06 - INFO - __main__ -   input_ids: 101 4788 2025 10678 2000 2020 12958 2147 2070 5263 2000 2031 1998 2012 2112 7057 6235 2678 1996 1050 1056 1996 2588 2006 1055 1998 1997 11333 1996 2000 1996 2518 1037 2029 2445 2391 6912 2216 8775 1997 2024 2589 7899 1037 1996 2023 1050 1056 2009 2033 2128 16969 2140 1999 2017 1055 2005 1050 1056 2122 1996 2131 7899 1045 2145 7561 2544 4469 1055 8775 2035 3642 2435 3857 3430 2000 2607 2022 3283 3277 1997 1997 4088 1999 1996 2622 6912 3178 2074 2129 2478 2130 2517 1996 2130 2172 1997 2045 1996 2009 2070 5371 2047 2205 2131 1996 2122 2008 6187 5210 5999 3642 2036 2607 7172 2009 2061 1999 2024 5371 3204 2551 2024 24185 2674 3143 2147 102\n",
      "12/06/2019 18:38:06 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "12/06/2019 18:38:06 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/06/2019 18:38:06 - INFO - __main__ -   label: 0 (id = 0)\n",
      "12/06/2019 18:38:06 - INFO - __main__ -   *** Example ***\n",
      "12/06/2019 18:38:06 - INFO - __main__ -   guid: test-2\n",
      "12/06/2019 18:38:06 - INFO - __main__ -   tokens: [CLS] interesting course on agriculture and economics very useful to rev ##ise important economic concept and also to learn more about agriculture highly recommended [SEP]\n",
      "12/06/2019 18:38:06 - INFO - __main__ -   input_ids: 101 5875 2607 2006 5237 1998 5543 2200 6179 2000 7065 5562 2590 3171 4145 1998 2036 2000 4553 2062 2055 5237 3811 6749 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/06/2019 18:38:06 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/06/2019 18:38:06 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/06/2019 18:38:06 - INFO - __main__ -   label: 2 (id = 2)\n",
      "12/06/2019 18:38:06 - INFO - __main__ -   *** Example ***\n",
      "12/06/2019 18:38:06 - INFO - __main__ -   guid: test-3\n",
      "12/06/2019 18:38:06 - INFO - __main__ -   tokens: [CLS] overall the video related to the quiz are to vague and un detailed i more often than not feel lost also this should not be part of the interaction design special ##isation and just be a small part of another course not once have i needed r or stat ##istic in my year design career [SEP]\n",
      "12/06/2019 18:38:06 - INFO - __main__ -   input_ids: 101 3452 1996 2678 3141 2000 1996 19461 2024 2000 13727 1998 4895 6851 1045 2062 2411 2084 2025 2514 2439 2036 2023 2323 2025 2022 2112 1997 1996 8290 2640 2569 6648 1998 2074 2022 1037 2235 2112 1997 2178 2607 2025 2320 2031 1045 2734 1054 2030 28093 6553 1999 2026 2095 2640 2476 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/06/2019 18:38:06 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/06/2019 18:38:06 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/06/2019 18:38:06 - INFO - __main__ -   label: 1 (id = 1)\n",
      "12/06/2019 18:38:06 - INFO - __main__ -   *** Example ***\n",
      "12/06/2019 18:38:06 - INFO - __main__ -   guid: test-4\n",
      "12/06/2019 18:38:06 - INFO - __main__ -   tokens: [CLS] tutor is russian i guess her accent is not quite understand ##able [SEP]\n",
      "12/06/2019 18:38:06 - INFO - __main__ -   input_ids: 101 14924 2003 2845 1045 3984 2014 9669 2003 2025 3243 3305 3085 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/06/2019 18:38:06 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/06/2019 18:38:06 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/06/2019 18:38:06 - INFO - __main__ -   label: 1 (id = 1)\n",
      "12/06/2019 18:38:06 - INFO - __main__ -   *** Example ***\n",
      "12/06/2019 18:38:06 - INFO - __main__ -   guid: test-5\n",
      "12/06/2019 18:38:06 - INFO - __main__ -   tokens: [CLS] but he are outline clear a not warned his ha definition [SEP]\n",
      "12/06/2019 18:38:06 - INFO - __main__ -   input_ids: 101 2021 2002 2024 12685 3154 1037 2025 7420 2010 5292 6210 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/06/2019 18:38:06 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/06/2019 18:38:06 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/06/2019 18:38:06 - INFO - __main__ -   label: 0 (id = 0)\n",
      "12/06/2019 18:38:07 - INFO - __main__ -   ***** Running evaluation on test set *****\n",
      "12/06/2019 18:38:07 - INFO - __main__ -     Num examples = 816\n",
      "12/06/2019 18:38:07 - INFO - __main__ -     Batch size = 8\n",
      "Evaluating: 100% 102/102 [00:12<00:00,  8.07it/s]\n",
      "Extracted pooled features for test set, congratulations!\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([816, 768])\n",
      "test features type :  <class 'numpy.ndarray'>\n",
      "test features shape :  (816, 768)\n",
      "test_labels type :  <class 'numpy.ndarray'>\n",
      "test_labels length :  816\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "==============================\n",
      "Accuracy with SVM: 0.9558823529411765\n",
      "==============================\n",
      "<class 'tuple'>\n",
      "(array([  8,  33,  36, 107, 114, 118, 129, 155, 245, 283, 301, 323, 328,\n",
      "       357, 361, 393, 405, 408, 415, 433, 484, 485, 530, 537, 543, 544,\n",
      "       555, 557, 566, 608, 706, 716, 729, 732, 777, 811]),)\n",
      "==============================\n",
      "[[275   8   5]\n",
      " [  9 261   6]\n",
      " [  2   6 244]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96       288\n",
      "           1       0.95      0.95      0.95       276\n",
      "           2       0.96      0.97      0.96       252\n",
      "\n",
      "    accuracy                           0.96       816\n",
      "   macro avg       0.96      0.96      0.96       816\n",
      "weighted avg       0.96      0.96      0.96       816\n",
      "\n",
      "==============================\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "<class 'tuple'>\n",
      "(array([  8,  36,  76, 107, 114, 129, 155, 211, 283, 301, 328, 357, 361,\n",
      "       379, 393, 405, 408, 415, 433, 474, 484, 485, 530, 537, 544, 555,\n",
      "       557, 566, 608, 624, 662, 706, 716, 729, 732, 777, 811]),)\n",
      "[[276   7   5]\n",
      " [ 10 258   8]\n",
      " [  2   5 245]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       288\n",
      "           1       0.96      0.93      0.95       276\n",
      "           2       0.95      0.97      0.96       252\n",
      "\n",
      "    accuracy                           0.95       816\n",
      "   macro avg       0.95      0.96      0.95       816\n",
      "weighted avg       0.95      0.95      0.95       816\n",
      "\n",
      "==============================\n",
      "Accuracy from Logistic Regression: 0.9546568627450981\n",
      "==============================\n",
      "Cumulative variance explained by 50 principal components: 0.9942238330841064\n",
      "t-SNE DONE for test data\n"
     ]
    }
   ],
   "source": [
    "!python Copy\\ of\\ extract_pooled_features_re.py --task_name SST-2 --do_eval --do_test --data_dir data_pooled_features --max_seq_length 128 --load_finetuned finetuned_for_pooled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "imsO5HDB1c_Q",
    "outputId": "b06b182f-e6b7-4e59-e345-1605c6d265fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " bertology.py                             \u001b[0m\u001b[01;34minput_data_t_d\u001b[0m/\n",
      "'Copy of extract_pooled_features_re.py'   \u001b[01;34minput_data_test\u001b[0m/\n",
      " \u001b[01;34mdata_pooled_features\u001b[0m/                    LICENSE\n",
      " \u001b[01;34mdocker\u001b[0m/                                  MANIFEST.in\n",
      " \u001b[01;34mdocs\u001b[0m/                                    \u001b[01;34mnotebooks\u001b[0m/\n",
      " \u001b[01;34mexamples\u001b[0m/                                plot_no_line_num_exp1.png\n",
      " extract_features.py                      plot_no_line_num.png\n",
      " extract_pooled_features_re.py            \u001b[01;34m__pycache__\u001b[0m/\n",
      " \u001b[01;34mfinetuned_bert\u001b[0m/                          \u001b[01;34mpytorch_pretrained_bert\u001b[0m/\n",
      " \u001b[01;34mfinetuned_bert2\u001b[0m/                         README.md\n",
      " \u001b[01;34mfinetuned_fold1\u001b[0m/                         requirements.txt\n",
      " \u001b[01;34mfinetuned_fold2\u001b[0m/                         run_classifier_dataset_utils.py\n",
      " \u001b[01;34mfinetuned_fold3\u001b[0m/                         run_classifier_py.py\n",
      " \u001b[01;34mfinetuned_fold4\u001b[0m/                         run_classifier_re.py\n",
      " \u001b[01;34mfinetuned_fold5\u001b[0m/                         run_gpt2.py\n",
      " \u001b[01;34mfinetuned_for_pooled_features\u001b[0m/           run_openai_gpt.py\n",
      " \u001b[01;34mfinetuned_test_result\u001b[0m/                   \u001b[01;34mruns\u001b[0m/\n",
      " \u001b[01;34mfold1\u001b[0m/                                   run_squad_dataset_utils.py\n",
      " \u001b[01;34mfold2\u001b[0m/                                   run_squad.py\n",
      " \u001b[01;34mfold3\u001b[0m/                                   run_swag.py\n",
      " \u001b[01;34mfold4\u001b[0m/                                   run_transfo_xl.py\n",
      " \u001b[01;34mfold5\u001b[0m/                                   \u001b[01;34msamples\u001b[0m/\n",
      " hubconf.py                               setup.py\n",
      " \u001b[01;34mhubconfs\u001b[0m/                                \u001b[01;34mtests\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "8OHvNxFcsskY",
    "outputId": "0616e4f1-dd15-47ee-fd23-198115eb98c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/03/2019 18:55:22 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "08/03/2019 18:55:22 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file finetuned_new_uncased/vocab.txt\n",
      "08/03/2019 18:55:22 - INFO - pytorch_pretrained_bert.modeling_re -   loading weights file finetuned_new_uncased/pytorch_model.bin\n",
      "08/03/2019 18:55:22 - INFO - pytorch_pretrained_bert.modeling_re -   loading configuration file finetuned_new_uncased/config.json\n",
      "08/03/2019 18:55:22 - INFO - pytorch_pretrained_bert.modeling_re -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "08/03/2019 18:55:29 - INFO - __main__ -   Writing example 0 of 184\n",
      "08/03/2019 18:55:29 - INFO - __main__ -   *** Example ***\n",
      "08/03/2019 18:55:29 - INFO - __main__ -   guid: dev-1\n",
      "08/03/2019 18:55:29 - INFO - __main__ -   tokens: [CLS] [UNK] ’ m not [UNK] licking toad ##s . [SEP]\n",
      "08/03/2019 18:55:29 - INFO - __main__ -   input_ids: 101 100 1521 1049 2025 100 17033 21344 2015 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "08/03/2019 18:55:29 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "08/03/2019 18:55:29 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "08/03/2019 18:55:29 - INFO - __main__ -   label: 0 (id = 0)\n",
      "08/03/2019 18:55:29 - INFO - __main__ -   *** Example ***\n",
      "08/03/2019 18:55:29 - INFO - __main__ -   guid: dev-2\n",
      "08/03/2019 18:55:29 - INFO - __main__ -   tokens: [CLS] @ gina ##aa & lt ; 3 [UNK] [UNK] [UNK] [UNK] [UNK] [SEP]\n",
      "08/03/2019 18:55:29 - INFO - __main__ -   input_ids: 101 1030 17508 11057 1004 8318 1025 1017 100 100 100 100 100 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "08/03/2019 18:55:29 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "08/03/2019 18:55:29 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "08/03/2019 18:55:29 - INFO - __main__ -   label: 2 (id = 2)\n",
      "08/03/2019 18:55:29 - INFO - __main__ -   *** Example ***\n",
      "08/03/2019 18:55:29 - INFO - __main__ -   guid: dev-3\n",
      "08/03/2019 18:55:29 - INFO - __main__ -   tokens: [CLS] that [UNK] should have a healthy lo ##athing of [UNK] . [UNK] not without reason . [SEP]\n",
      "08/03/2019 18:55:29 - INFO - __main__ -   input_ids: 101 2008 100 2323 2031 1037 7965 8840 22314 1997 100 1012 100 2025 2302 3114 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "08/03/2019 18:55:29 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "08/03/2019 18:55:29 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "08/03/2019 18:55:29 - INFO - __main__ -   label: 0 (id = 0)\n",
      "08/03/2019 18:55:29 - INFO - __main__ -   *** Example ***\n",
      "08/03/2019 18:55:29 - INFO - __main__ -   guid: dev-4\n",
      "08/03/2019 18:55:29 - INFO - __main__ -   tokens: [CLS] # poems ##under ##14 ##0 . . . . started by @ shannon ##ely ##se ##1 [SEP]\n",
      "08/03/2019 18:55:29 - INFO - __main__ -   input_ids: 101 1001 5878 20824 16932 2692 1012 1012 1012 1012 2318 2011 1030 10881 26006 3366 2487 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "08/03/2019 18:55:29 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "08/03/2019 18:55:29 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "08/03/2019 18:55:29 - INFO - __main__ -   label: 2 (id = 2)\n",
      "08/03/2019 18:55:29 - INFO - __main__ -   *** Example ***\n",
      "08/03/2019 18:55:29 - INFO - __main__ -   guid: dev-5\n",
      "08/03/2019 18:55:29 - INFO - __main__ -   tokens: [CLS] [UNK] dog riding the bicycle http : / / bit . l ##y / [UNK] [SEP]\n",
      "08/03/2019 18:55:29 - INFO - __main__ -   input_ids: 101 100 3899 5559 1996 10165 8299 1024 1013 1013 2978 1012 1048 2100 1013 100 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "08/03/2019 18:55:29 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "08/03/2019 18:55:29 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "08/03/2019 18:55:29 - INFO - __main__ -   label: 2 (id = 2)\n",
      "08/03/2019 18:55:29 - INFO - __main__ -   ***** Running evaluation *****\n",
      "08/03/2019 18:55:29 - INFO - __main__ -     Num examples = 184\n",
      "08/03/2019 18:55:29 - INFO - __main__ -     Batch size = 8\n",
      "Evaluating: 100% 23/23 [00:01<00:00, 13.07it/s]\n",
      "Extracted pooled features! congratulations\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([184, 768])\n",
      "<class 'numpy.ndarray'>\n",
      "(184, 768)\n",
      "<class 'numpy.ndarray'>\n",
      "184\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "Accuracy with SVM: 0.9459459459459459\n",
      "<class 'tuple'>\n",
      "(array([6, 8]),)\n",
      "[[ 7  1  0]\n",
      " [ 1  9  0]\n",
      " [ 0  0 19]]\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "<class 'tuple'>\n",
      "(array([6, 8]),)\n",
      "[[ 7  1  0]\n",
      " [ 1  9  0]\n",
      " [ 0  0 19]]\n",
      "Accuracy from Logistic Regression: 0.9459459459459459\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "Logistic Regression 0.9621298742351374\n",
      "==============================\n",
      "Linear SVM 0.9567165661902506\n",
      "==============================\n",
      "RBF SVM 0.9343184537921381\n",
      "==============================\n",
      "Decision Tree 0.945897852739958\n",
      "==============================\n",
      "Random Forest 0.9565578360315203\n",
      "==============================\n",
      "AdaBoost 0.957008963851069\n",
      "==============================\n",
      "Cumulative variance explained by 50 principal components: 0.995897114276886\n",
      "t-SNE DONE\n"
     ]
    }
   ],
   "source": [
    "!python extract_pooled_features_re.py --task_name SST-2 --do_eval --data_dir input_data_pyt --max_seq_length 128 --train_batch_size 8 --learning_rate 2e-5 --num_train_epochs 3.0 --load_finetuned finetuned_new_uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-TzZ2dvyspUp",
    "outputId": "584529ca-6c14-4e79-c966-562d8f786e27"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FlP7VDCsoyjy",
    "outputId": "584529ca-6c14-4e79-c966-562d8f786e27"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "opKvAg503X25",
    "outputId": "28996c32-81af-4c78-ad9c-189f8f0f194c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wkpsar-jnfx8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy_of_BERT_pytorch_pooled_features.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
